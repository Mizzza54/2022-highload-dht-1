# Отчет по 3 стадии

### Я фулл хз почему на винде и на линуксе так отличаются результаты профилирования, поэтому когда я говорю так же как и было до шардирования, я повторил тест на винде и сравнил 

### !!!!!!!!!! Такие низкие показатели ордеррейта потому что рабочий антивирус eset при нагрузке начинает резко сжирать 60-70% cpu.

Была взята rockDB реализация базы данных. И до начала тестирования нагружена данными примерно на 15.6GB суммарно на 3 узла

Несмотря на все трудности с async-profiler, я почти смог его победить. Подебажив async-profiler получилось 
заставить его работать на wsl, теперь в отчетах будет хитмапа, но с профилированием локов все еще проблемы. При 
конвертации в html из jfr, jrf2flame отказывается конвертировать локи, хотя информация о них собиралась во время
профилирования.

По сравнению с прошлым этапом, было добавлено шардирование кластера на несколько нод.
После ресолва реквеста в сервис и проверки запроса на минимальную корректность 
с помощью NodeRouters(использующего Jumping hashes в сочетании с Hash.murmur3, отличающейся максимально честным 
распределением по нодам и возможность добавления нод(но не удаления)
по ключу вычисляется подходящая нода для переадресовки запроса.

Кроме того был реализован circuit breaker(так что дайте бонус!!!), использующий Scheduled thread pool.
При обнаружении дисконекта ноды, все запросы на нее начинают реджектится и создается таска раз в 5 секунд
мониторящая доступность ноды, которая открывает доступ к ней при подъеме.

В отчете будут отражены результаты подачи нагрузки через первую ноду, но за кадром была протестирована
нагрузка на все ноды. 

Кроме того, стоит отметить, что из-за подхода использующегося в предыдущем дз с распараллеливанием на уровне
сервера и нежеланием нарушать все возможные принципы инкапсуляции с выполнение работы сервиса в сервере,
не было возможность добавить отдельный тредпул для асинхронного редиректа запросов, и редирект происходит
в основном тредпуле для записи данных(что на самом деле не особо и проблема то).

Стоит отметить, что неочевидной причиной дергадации перформанса мог быть переезд на wsl(в профайлинге очевидно мы это не увидим,
но я подозреваю что накладные расходы все таки присутствуют)

Более очевидными проблемами деградации перформанса являются: 
1. Возросшая в 3 раза нагрузка на ресурсы компьютера(ноды то локально поднимаются). А если бы поднимались не локально,
сеть бы передала привет(хотя про нее дальше).
2. Возросшая сетевая нагрузка мастер узла. Отправка и прием редеректнутого запроса на другой узел совсем 
не бесплатная. По сути мы почти в 2/3 раза сильнее нагружаем сеть узла.
3. Использование circuit breaker тоже не дается бесплатно(нам все еще нужен тредпул для мониторинга доступности нод),
хоть и дает куда больше импакта, из-за того, что мы не тратим время на попытки отправки заведомо мертвых запросов,
а сразу их реджектим.


Далее я приведу результаты профилирования с минимальными комментариями по возможным улучшениям и отличиям от предыдущих этапов
(писать пасту про то у кого сколько процентов не вижу смысла, это очевидно видно из флейм графа).
   
# Профилирование
## PUT
### Latency(wrk2)
```
Running 2m test @ http://localhost:19234
  8 threads and 8 connections
  Thread calibration: mean lat.: 3.097ms, rate sampling interval: 10ms
  Thread calibration: mean lat.: 3.192ms, rate sampling interval: 10ms
  Thread calibration: mean lat.: 3.227ms, rate sampling interval: 10ms
  Thread calibration: mean lat.: 3.225ms, rate sampling interval: 10ms
  Thread calibration: mean lat.: 3.179ms, rate sampling interval: 10ms
  Thread calibration: mean lat.: 3.224ms, rate sampling interval: 10ms
  Thread calibration: mean lat.: 3.236ms, rate sampling interval: 10ms
  Thread calibration: mean lat.: 3.270ms, rate sampling interval: 10ms
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency     6.68ms   10.21ms 108.80ms   92.05%
    Req/Sec   526.57     84.90     1.00k    75.52%
  Latency Distribution (HdrHistogram - Recorded Latency)
 50.000%    3.51ms
 75.000%    5.35ms
 90.000%   12.49ms
 99.000%   55.87ms
 99.900%   85.44ms
 99.990%  104.51ms
 99.999%  108.29ms
100.000%  108.86ms

  Detailed Percentile spectrum:
       Value   Percentile   TotalCount 1/(1-Percentile)

       0.650     0.000000            1         1.00
       1.987     0.100000        44034         1.11
       2.433     0.200000        88072         1.25
       2.799     0.300000       132220         1.43
       3.139     0.400000       175997         1.67
       3.509     0.500000       220162         2.00
       3.723     0.550000       242049         2.22
       3.981     0.600000       264091         2.50
       4.307     0.650000       286132         2.86
       4.735     0.700000       308087         3.33
       5.347     0.750000       329982         4.00
       5.771     0.775000       341046         4.44
       6.319     0.800000       351976         5.00
       7.055     0.825000       362977         5.71
       8.067     0.850000       374008         6.67
       9.623     0.875000       384991         8.00
      10.847     0.887500       390488         8.89
      12.487     0.900000       395974        10.00
      14.951     0.912500       401472        11.43
      18.271     0.925000       406982        13.33
      22.783     0.937500       412476        16.00
      25.327     0.943750       415229        17.78
      28.095     0.950000       417991        20.00
      30.639     0.956250       420721        22.86
      34.303     0.962500       423496        26.67
      38.559     0.968750       426238        32.00
      40.575     0.971875       427598        35.56
      42.239     0.975000       428978        40.00
      43.775     0.978125       430369        45.71
      45.823     0.981250       431730        53.33
      48.415     0.984375       433100        64.00
      49.823     0.985938       433786        71.11
      52.127     0.987500       434475        80.00
      54.623     0.989062       435157        91.43
      56.863     0.990625       435845       106.67
      59.615     0.992188       436532       128.00
      60.735     0.992969       436886       142.22
      61.919     0.993750       437220       160.00
      63.263     0.994531       437564       182.86
      64.831     0.995313       437909       213.33
      67.775     0.996094       438255       256.00
      69.119     0.996484       438430       284.44
      70.847     0.996875       438599       320.00
      71.999     0.997266       438767       365.71
      73.407     0.997656       438939       426.67
      75.007     0.998047       439114       512.00
      75.647     0.998242       439197       568.89
      76.479     0.998437       439285       640.00
      77.503     0.998633       439369       731.43
      80.255     0.998828       439455       853.33
      86.911     0.999023       439541      1024.00
      90.111     0.999121       439583      1137.78
      93.567     0.999219       439628      1280.00
      96.511     0.999316       439669      1462.86
      98.239     0.999414       439713      1706.67
     100.159     0.999512       439755      2048.00
     100.607     0.999561       439776      2275.56
     100.927     0.999609       439798      2560.00
     101.439     0.999658       439822      2925.71
     102.079     0.999707       439841      3413.33
     102.719     0.999756       439862      4096.00
     103.039     0.999780       439873      4551.11
     103.359     0.999805       439886      5120.00
     103.551     0.999829       439895      5851.43
     103.935     0.999854       439905      6826.67
     104.127     0.999878       439916      8192.00
     104.383     0.999890       439921      9102.22
     104.831     0.999902       439927     10240.00
     105.343     0.999915       439932     11702.86
     106.239     0.999927       439937     13653.33
     107.135     0.999939       439943     16384.00
     107.199     0.999945       439945     18204.44
     107.327     0.999951       439948     20480.00
     107.583     0.999957       439952     23405.71
     107.647     0.999963       439954     27306.67
     107.711     0.999969       439956     32768.00
     107.775     0.999973       439957     36408.89
     107.967     0.999976       439959     40960.00
     108.031     0.999979       439960     46811.43
     108.159     0.999982       439963     54613.33
     108.159     0.999985       439963     65536.00
     108.159     0.999986       439963     72817.78
     108.223     0.999988       439964     81920.00
     108.287     0.999989       439967     93622.86
     108.287     0.999991       439967    109226.67
     108.287     0.999992       439967    131072.00
     108.287     0.999993       439967    145635.56
     108.287     0.999994       439967    163840.00
     108.287     0.999995       439967    187245.71
     108.287     0.999995       439967    218453.33
     108.607     0.999996       439968    262144.00
     108.607     0.999997       439968    291271.11
     108.607     0.999997       439968    327680.00
     108.607     0.999997       439968    374491.43
     108.607     0.999998       439968    436906.67
     108.863     0.999998       439969    524288.00
     108.863     1.000000       439969          inf
#[Mean    =        6.676, StdDeviation   =       10.213]
#[Max     =      108.800, Total count    =       439969]
#[Buckets =           27, SubBuckets     =         2048]
----------------------------------------------------------
  479988 requests in 2.00m, 37.98MB read
Requests/sec:   4000.01
Transfer/sec:    324.14KB
```
### Flame graph
#### Cpu
1. Сильно уменьшилась доля RocksDB.put(). Неудивительно, ведь уменьшили в 3 раза нагрузку на нашу ноду
2. Появился HttpClient.invoke() отвечающий за отправку и прием редиректнутого сообщения


А теперь самый треш. Это отличия от такого же теста на винде. В остальном тест на винде == тест на винде до шардов
1. Увеличилось время ожидание появления таски в пуле await в 5 раз (Очередь пустая? Не успел нормально дотестить мб проблема что сеть не вывозит ордеррейт) 
4. Увеличилось время select (казалось бы лол, как сеть может не вывозить в таком случае)

Формально их увеличение говорит нам о простое системы и можно было бы без задней мысли увеличить рейт. Но нельзя. Латенси
улетит куда-то в небеса, а процентное соотношение блоков тут как тут(по 15 процентов примерно каждый от корня).
Возможные проблемы:
мой рабочий антивирус тротлит(хз надо мужикам код отправить)


![put_cpu_merged](put_cpu_all.png)

#### Alloc
По хитмапе видно, что аллокациям очень больно.
Так же появилсь аллокации в invoke, а в остальном очень похоже на не шардированную версию.
![put_alloc_merged](put_alloc_all.png)

#### Lock
Появились аллокации для HttpClient.invoke(). Которые как не странно уходят на пересылку объекта по сети.
В остальном так же. Большая часть локов на вынимание элементов из очереди
![put_lock_worker](put_lock_all.png)


# GET
### Latency(wrk2)
```
Running 2m test @ http://localhost:19234
  8 threads and 8 connections
  Thread calibration: mean lat.: 6.089ms, rate sampling interval: 22ms
  Thread calibration: mean lat.: 7.478ms, rate sampling interval: 26ms
  Thread calibration: mean lat.: 5.650ms, rate sampling interval: 19ms
  Thread calibration: mean lat.: 6.082ms, rate sampling interval: 20ms
  Thread calibration: mean lat.: 5.863ms, rate sampling interval: 19ms
  Thread calibration: mean lat.: 6.013ms, rate sampling interval: 20ms
  Thread calibration: mean lat.: 6.243ms, rate sampling interval: 22ms
  Thread calibration: mean lat.: 7.712ms, rate sampling interval: 28ms
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency     8.72ms   11.13ms 100.35ms   93.39%
    Req/Sec   383.93     42.84   631.00     71.49%
  Latency Distribution (HdrHistogram - Recorded Latency)
 50.000%    5.49ms
 75.000%    8.57ms
 90.000%   14.57ms
 99.000%   67.58ms
 99.900%   84.99ms
 99.990%   95.94ms
 99.999%   99.58ms
100.000%  100.42ms

  Detailed Percentile spectrum:
       Value   Percentile   TotalCount 1/(1-Percentile)

       0.936     0.000000            1         1.00
       2.957     0.100000        33011         1.11
       3.669     0.200000        66066         1.25
       4.219     0.300000        99176         1.43
       4.787     0.400000       132163         1.67
       5.491     0.500000       165162         2.00
       5.915     0.550000       181562         2.22
       6.395     0.600000       197992         2.50
       6.971     0.650000       214534         2.86
       7.675     0.700000       231048         3.33
       8.567     0.750000       247540         4.00
       9.111     0.775000       255841         4.44
       9.735     0.800000       263990         5.00
      10.479     0.825000       272292         5.71
      11.399     0.850000       280546         6.67
      12.647     0.875000       288751         8.00
      13.487     0.887500       292861         8.89
      14.567     0.900000       296998        10.00
      15.999     0.912500       301124        11.43
      17.967     0.925000       305243        13.33
      20.911     0.937500       309362        16.00
      23.039     0.943750       311436        17.78
      25.999     0.950000       313485        20.00
      30.159     0.956250       315546        22.86
      35.583     0.962500       317609        26.67
      42.367     0.968750       319672        32.00
      45.727     0.971875       320706        35.56
      49.247     0.975000       321737        40.00
      53.791     0.978125       322768        45.71
      57.055     0.981250       323797        53.33
      60.447     0.984375       324828        64.00
      62.079     0.985938       325349        71.11
      63.999     0.987500       325869        80.00
      65.983     0.989062       326387        91.43
      68.863     0.990625       326898       106.67
      71.103     0.992188       327416       128.00
      72.319     0.992969       327671       142.22
      73.471     0.993750       327933       160.00
      74.495     0.994531       328190       182.86
      75.647     0.995313       328437       213.33
      77.119     0.996094       328702       256.00
      77.759     0.996484       328826       284.44
      78.399     0.996875       328952       320.00
      79.231     0.997266       329087       365.71
      80.191     0.997656       329211       426.67
      81.279     0.998047       329339       512.00
      81.791     0.998242       329405       568.89
      82.367     0.998437       329468       640.00
      83.071     0.998633       329533       731.43
      83.839     0.998828       329599       853.33
      85.119     0.999023       329660      1024.00
      85.887     0.999121       329696      1137.78
      86.719     0.999219       329730      1280.00
      87.423     0.999316       329757      1462.86
      88.319     0.999414       329789      1706.67
      89.471     0.999512       329824      2048.00
      89.855     0.999561       329839      2275.56
      90.431     0.999609       329854      2560.00
      91.007     0.999658       329871      2925.71
      91.519     0.999707       329887      3413.33
      92.095     0.999756       329903      4096.00
      92.415     0.999780       329910      4551.11
      93.567     0.999805       329919      5120.00
      94.719     0.999829       329928      5851.43
      95.039     0.999854       329934      6826.67
      95.551     0.999878       329943      8192.00
      95.807     0.999890       329946      9102.22
      95.999     0.999902       329950     10240.00
      96.383     0.999915       329954     11702.86
      96.639     0.999927       329958     13653.33
      97.087     0.999939       329962     16384.00
      97.279     0.999945       329964     18204.44
      97.471     0.999951       329967     20480.00
      97.535     0.999957       329968     23405.71
      97.919     0.999963       329970     27306.67
      98.239     0.999969       329972     32768.00
      98.495     0.999973       329973     36408.89
      98.751     0.999976       329974     40960.00
      99.071     0.999979       329975     46811.43
      99.263     0.999982       329976     54613.33
      99.391     0.999985       329977     65536.00
      99.455     0.999986       329978     72817.78
      99.455     0.999988       329978     81920.00
      99.583     0.999989       329979     93622.86
      99.583     0.999991       329979    109226.67
     100.095     0.999992       329980    131072.00
     100.095     0.999993       329980    145635.56
     100.095     0.999994       329980    163840.00
     100.159     0.999995       329981    187245.71
     100.159     0.999995       329981    218453.33
     100.159     0.999996       329981    262144.00
     100.159     0.999997       329981    291271.11
     100.159     0.999997       329981    327680.00
     100.415     0.999997       329982    374491.43
     100.415     1.000000       329982          inf
#[Mean    =        8.722, StdDeviation   =       11.130]
#[Max     =      100.352, Total count    =       329982]
#[Buckets =           27, SubBuckets     =         2048]
----------------------------------------------------------
  359990 requests in 2.00m, 1.86GB read
Requests/sec:   2999.99
Transfer/sec:     15.89MB

```
### Flame graph
#### Cpu
Все наблюдения из пута актуальны и тут. Ничего нового.
![get_cpu_merged](get_cpu.png)

#### Alloc
Все так же как и до шардирования, кроме опять же аллокаций на invoke(нет не оптимизируем).
![get_alloc_merged](get_alloc.png)

#### Lock
Так же как до + так же как в пут
![get_lock_merged](get_lock.png)



# FalenNode
Теперь покажу результаты если отключить ноду во время тестирования. Покажу только для пут и только cpu, стальное не интересно.


## PUT
### Latency(wrk2)
```
Running 2m test @ http://localhost:19234
  16 threads and 16 connections
  Thread calibration: mean lat.: 3.040ms, rate sampling interval: 10ms
  Thread calibration: mean lat.: 3.074ms, rate sampling interval: 10ms
  Thread calibration: mean lat.: 3.060ms, rate sampling interval: 10ms
  Thread calibration: mean lat.: 3.067ms, rate sampling interval: 10ms
  Thread calibration: mean lat.: 3.037ms, rate sampling interval: 10ms
  Thread calibration: mean lat.: 3.070ms, rate sampling interval: 10ms
  Thread calibration: mean lat.: 3.072ms, rate sampling interval: 10ms
  Thread calibration: mean lat.: 3.051ms, rate sampling interval: 10ms
  Thread calibration: mean lat.: 3.063ms, rate sampling interval: 10ms
  Thread calibration: mean lat.: 3.044ms, rate sampling interval: 10ms
  Thread calibration: mean lat.: 3.069ms, rate sampling interval: 10ms
  Thread calibration: mean lat.: 3.074ms, rate sampling interval: 10ms
  Thread calibration: mean lat.: 3.059ms, rate sampling interval: 10ms
  Thread calibration: mean lat.: 3.034ms, rate sampling interval: 10ms
  Thread calibration: mean lat.: 3.079ms, rate sampling interval: 10ms
  Thread calibration: mean lat.: 3.067ms, rate sampling interval: 10ms
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   104.55ms  505.50ms   4.56s    95.42%
    Req/Sec   264.24     88.90     1.00k    92.33%
  Latency Distribution (HdrHistogram - Recorded Latency)
 50.000%    2.75ms
 75.000%    3.59ms
 90.000%    4.75ms
 99.000%    3.07s 
 99.900%    4.46s 
 99.990%    4.55s 
 99.999%    4.56s 
100.000%    4.57s 

  Detailed Percentile spectrum:
       Value   Percentile   TotalCount 1/(1-Percentile)

       0.606     0.000000            1         1.00
       1.605     0.100000        44040         1.11
       1.960     0.200000        87998         1.25
       2.229     0.300000       132094         1.43
       2.485     0.400000       176163         1.67
       2.753     0.500000       220289         2.00
       2.891     0.550000       242042         2.22
       3.043     0.600000       263976         2.50
       3.211     0.650000       286204         2.86
       3.391     0.700000       308049         3.33
       3.593     0.750000       330103         4.00
       3.701     0.775000       341136         4.44
       3.819     0.800000       352080         5.00
       3.955     0.825000       363081         5.71
       4.131     0.850000       374204         6.67
       4.363     0.875000       384973         8.00
       4.527     0.887500       390514         8.89
       4.751     0.900000       395986        10.00
       5.159     0.912500       401473        11.43
       6.615     0.925000       406962        13.33
      19.103     0.937500       412461        16.00
      44.319     0.943750       415211        17.78
     375.295     0.950000       417964        20.00
     729.087     0.956250       420711        22.86
    1086.463     0.962500       423460        26.67
    1449.983     0.968750       426210        32.00
    1639.423     0.971875       427588        35.56
    1828.863     0.975000       428966        40.00
    2021.375     0.978125       430340        45.71
    2201.599     0.981250       431721        53.33
    2390.015     0.984375       433084        64.00
    2480.127     0.985938       433780        71.11
    2652.159     0.987500       434459        80.00
    2912.255     0.989062       435150        91.43
    3160.063     0.990625       435837       106.67
    3407.871     0.992188       436522       128.00
    3528.703     0.992969       436867       142.22
    3659.775     0.993750       437210       160.00
    3782.655     0.994531       437555       182.86
    3905.535     0.995313       437899       213.33
    4026.367     0.996094       438240       256.00
    4093.951     0.996484       438418       284.44
    4155.391     0.996875       438589       320.00
    4218.879     0.997266       438758       365.71
    4280.319     0.997656       438929       426.67
    4341.759     0.998047       439100       512.00
    4370.431     0.998242       439190       568.89
    4399.103     0.998437       439283       640.00
    4423.679     0.998633       439372       731.43
    4444.159     0.998828       439456       853.33
    4468.735     0.999023       439540      1024.00
    4476.927     0.999121       439578      1137.78
    4485.119     0.999219       439621      1280.00
    4497.407     0.999316       439676      1462.86
    4505.599     0.999414       439712      1706.67
    4517.887     0.999512       439761      2048.00
    4521.983     0.999561       439784      2275.56
    4526.079     0.999609       439806      2560.00
    4530.175     0.999658       439823      2925.71
    4534.271     0.999707       439841      3413.33
    4538.367     0.999756       439862      4096.00
    4538.367     0.999780       439862      4551.11
    4542.463     0.999805       439876      5120.00
    4546.559     0.999829       439899      5851.43
    4546.559     0.999854       439899      6826.67
    4550.655     0.999878       439917      8192.00
    4550.655     0.999890       439917      9102.22
    4550.655     0.999902       439917     10240.00
    4554.751     0.999915       439933     11702.86
    4554.751     0.999927       439933     13653.33
    4554.751     0.999939       439933     16384.00
    4558.847     0.999945       439944     18204.44
    4558.847     0.999951       439944     20480.00
    4558.847     0.999957       439944     23405.71
    4558.847     0.999963       439944     27306.67
    4562.943     0.999969       439954     32768.00
    4562.943     0.999973       439954     36408.89
    4562.943     0.999976       439954     40960.00
    4562.943     0.999979       439954     46811.43
    4562.943     0.999982       439954     54613.33
    4562.943     0.999985       439954     65536.00
    4562.943     0.999986       439954     72817.78
    4562.943     0.999988       439954     81920.00
    4562.943     0.999989       439954     93622.86
    4562.943     0.999991       439954    109226.67
    4567.039     0.999992       439958    131072.00
    4567.039     1.000000       439958          inf
#[Mean    =      104.553, StdDeviation   =      505.496]
#[Max     =     4562.944, Total count    =       439958]
#[Buckets =           27, SubBuckets     =         2048]
----------------------------------------------------------
  479993 requests in 2.00m, 36.90MB read
  Socket errors: connect 0, read 0, write 0, timeout 6
  Non-2xx or 3xx responses: 93833
Requests/sec:   4000.21
Transfer/sec:    314.91KB

```
### Flame graph
#### Cpu

А тут интересно, можно заметить разрыв посередине хитмапы. Он связан с тем, что треды в пуле забились тасками к 
упавшей ноде и пока они не таймаутнулись 1 раз и не поставили блокировку на конект вся система висела, после этого сразу
все запросы к ноде реджектились. Я вам не показал, но если восстановить ноду, ты запрсы к ней будут проходить все норм.

![put_cpu_merged](put_cpu_fallen_node.png)


Так выглядит мониторящий тред, вполне здоров, спит, конектится, что еще нужно?

![monitoring](monitoring_thread_cpu.png)