# Отчет

## Введение

Был исправлен spring-style из предыдущего этапа. Явным переопределением метода `handleRequest`, чтобы избежать лишней
работы.

Дальнейший анализ проходил на кластере из 3 узлов на трех разных jvm процессах. Мастер системой был выбран первый узел.

## Небольшие трудности.

Хотелось здесь зафиксировать две проблемки, которые возникли в ходе выполнения работы. Первая проблема - это что
хеш-функции двух последовательных строк ("1000", "1001") почти неразличима. Вторая, используя консистетное хеширование,
что хеши урлов узлов располагаются на круге слишком рядом.

Первая проблема поправима с помощью `Hash.murmur3`. Для решения второй результат Hash.murmur3 я еще конкатинирую с
номером точки на круге.

Самое важное, чтобы эти параметры совпадали на разных узлах.

## Ход работы.

Начнем с нагрузки в 50k rps.

Нагрузку 50k rps теперь кластер не выдерживает.

```
kurdyukov-kir@i109817004 lua % wrk2 -d 2m -c 64 -t 64 -s put_http_query.lua -R 50000 http://localhost:4242
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency    31.05s    16.34s    1.06m    58.58%
    Req/Sec   379.07     33.26   441.00     57.85%
  2884011 requests in 2.00m, 169.16MB read
  Non-2xx or 3xx responses: 5952
Requests/sec:  24036.07
```

Это обусловлено тем, что:

1. Теперь ресурсов компьютера тратятся в 3 раза больше. Так как мы поднимаем ноды локально.
2. Нагрузка мастер - узла выросла в два раза, так как запрос, который он делегирует на другой узел, вынужден будет ему
   ответить. Тем самым один запрос плодит два http - запроса на мастер - ноду.
3. В нашей системе появились дополнительные походы по сети между нодами.

Посмотрим как распределились данные после 2х минутной нагрузке. Даже несмотря на то, что кластер захлебнулся.

```
kurdyukov-kir@i109817004 ~ % du -sh data1
 27M	data1
kurdyukov-kir@i109817004 ~ % du -sh data2
 18M	data2
kurdyukov-kir@i109817004 ~ % du -sh data3
 21M	data3
```

При использовании консистетного хеширования данные распределяются +- равномерно. Это с учетом, что мы пишем ключи
последовательно. Здесь нас спасает `Hash.murmur3`. Так как иначе все ключи укладывались в один отрезок. Можно
увеличивать количество виртуальных узлов, чтобы распределение было еще более равномерным.

В условиях того, что наша система не изменяется (не добавляется / не удаляется нода). То себя здесь хорошо будет
показывать простое шардирование "по модулю" хеша ключа. Ключи у нас тем более идут последовательно, то распределение
будет равномерное. Но это никак не коррелирует с реальной жизнью. Вдруг нам захочется динамически изменять кластер, а
также мы не знаем какие ключи будут у пользователя. Также злоумышленник может узнать об нашей хешфункции и специально
нагружать одну ноду. В консистетном хешировании он будет попадать на разные участки круга, ему нужно будет учитывать и
этот факт. Рандеву хеширование - плохо тем, что всегда работает за размер кластера. А также имеет проблемы с удалением /
добавлением ноды. Тоже переезжает большое количество ключей.

Соответственно результаты "простого" шаридирования:

```
kurdyukov-kir@i109817004 ~ % du -sh data1
 24M	data1
kurdyukov-kir@i109817004 ~ % du -sh data2
 24M	data2
kurdyukov-kir@i109817004 ~ % du -sh data3
 23M	data3
```

В целом ожидаемый хороший результат. Хеши почти одинаковых строк почти равны ("100", "101"), поэтому мы распределяем
почти последовательно. Ключи распределяются "слоями". Но этот метод шардирования не подходит для продакшена по причинам,
перечисленным выше. Поэтому дальнейший анализ будет с консистетным хешированием производиться.

К слову 30к rps мы также не выдерживаем.

Сейчас кластер способен выдерживать 15к rps.

```
kurdyukov-kir@i109817004 lua % wrk2 -d 2m -c 64 -t 64 -s put_http_query.lua -R 15000 http://localhost:4242
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency     7.71ms   44.20ms 487.42ms   97.77%
    Req/Sec   233.98      7.87   294.00     96.34%
  1799968 requests in 2.00m, 105.53MB read
  Non-2xx or 3xx responses: 2327
```

2327 - не удачных запросов наверно вызвано тем, что не находиться свободного потока, который бы обработал задачу
клиента, и мы получаем режект.

Профилирование [cpu](./profiler/png/put_cpu.png) и [alloc](./profiler/png/put_cpu.png) показывает, что клиент сильно
нагрузил кластер. Очень много CPU уходит на парковку треда и на работу с сетью - почти все вызовы утыкаются либо в
системный вызов или парковку треда. И асинхронную обработку ответа другой ноды. Аллокации тоже почти все уходят на
работу с сетью.

Что сразу наводит на мысли использования более низкоуровневого протокола как TCP. Либо использования другого API для
клиента.

[lock](./profiler/png/put_lock.png) Также по локам клиент превзошел базу. Почти все локи были взяты клиентским
селектором.

Get тоже 15к rps

```
kurdyukov-kir@i109817004 lua % wrk2 -d 1m -c 64 -t 64 -s get_http_query.lua -R 15000 http://localhost:4242
Running 1m test @ http://localhost:4242
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency     1.00ms  453.77us   7.84ms   73.44%
    Req/Sec   233.99      0.12   235.00    100.00%
  899983 requests in 1.00m, 657.08MB read
  Non-2xx or 3xx responses: 291
Requests/sec:  15002.00
Transfer/sec:     10.95MB  
```

Профилирование [cpu](./profiler/png/get_cpu.png), [alloc](./profiler/png/get_alloc.png),
[lock](./profiler/png/get_lock.png) показывают те же результаты, что и на PUT.

## Выводы

Клиент оказался серьезной нагрузкой для узлов нашего кластера. Все cpu, alloc, lock исходят от нашего клиента. Заметен
ряд улучшений:

1. Можно разделить мастер системы и узел нашего кластера. Т.е отдельный кластер для шардирования, другой для самих
   узлов.
2. Переход на более низкий протокол.
3. Смена Api клиента.

При выполнении дз было замечено, что при больших нагрузках клиенту не хватает тредпула фиксированного размера. Поэтому
клиент сейчас пользуется CachedThreadPool. В дальнейших лекциях нам должны рассказать об правильном асинхронном
программировании.

Консистетное хеширование показало себя достойно - как способ шардирования. Можно как улучшение увеличить число
виртуальных нод.

Можно отметить, что просто способ шардирования был очень хорош в рамках обстрела из wrk2.

Также заметно улучшилось производительность GET'ов. Связано это с тем, что поход в диск дешевле, чем поход по сети.

## Дополнительно был сделан простой вариант Circuit Breaker

Хотел пометить как потенциальное улучшение, что в ситуации отказа ноды у нас не забивался тредпул таймаутами на упавшую
ноду.
Но в итоге реализовал. Мы продолжаем стабильно работать с оставшимся нодами.

Итак, запускаем заполненную базу на 3 узла. Но отключив одну из нод.

```
wrk2 -d 1m -c 64 -t 64 -s get_http_query.lua -R 5000 http://localhost:4242

Thread Stats   Avg      Stdev     Max   +/- Stdev
Latency     1.54ms    1.28ms  28.80ms   95.61%
Req/Sec    82.24     41.27   333.00     80.31%
300053 requests in 1.00m, 142.90MB read
Non-2xx or 3xx responses: 116880
```

Ожидаемо замечаем, что треть запросов уходит мимо. Приятно, что треть! Значит консистетное хеширование имеет хорошее
распределение!)

Затем поднимаем третью ноду.

Листенер пингует мертвую ноду с интервалом полсекунды.

```
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency     1.35ms    1.29ms  55.78ms   98.93%
    Req/Sec    82.15     40.24   555.00     81.18%
  300044 requests in 1.00m, 219.11MB read
  Non-2xx or 3xx responses: 26
```

Супер! нода ожила и работает исправно! Флажок засетился! Также снова мы защитимся и при отключении!

Из минусов - накладные рассходы на листенер :( 

Повод задуматься об оптимизация - убрать листенер, сделать более умную логику.